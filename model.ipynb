{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Price Prediction with Random Forest Case Study Yogyakarta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import semua library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset yang sudah dibersihkan sebelumnya\n",
    "dataset = pd.read_csv(\"data/rumahcom_clean.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melihat tipe data yang ada di setiap field\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengecek jumlah data yang tidak kosong\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat statistika deskriptif dari data\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat korelas antar field\n",
    "# dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 4])\n",
    "sns.histplot(data=dataset, x=dataset[\"harga\"], color='g', kde=True, edgecolor=\"black\", linewidth=2, bins=30)\n",
    "plt.title('Distribusi variabel target (harga)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a file exists\n",
    "def file_exists(filename):\n",
    "    try:\n",
    "        with open(filename):\n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the preprocessed data is already available\n",
    "data_cache_file = \"cache/data_cache.joblib\"\n",
    "if file_exists(data_cache_file):\n",
    "    data, X_encoded, y = joblib.load(data_cache_file)\n",
    "else:\n",
    "    # Read the CSV file if data is not cached\n",
    "    data = pd.read_csv(\"data/rumahcom_clean.csv\")\n",
    "\n",
    "    # Prepare data\n",
    "    X = data[[\"lokasi\", \"luas_bangunan\", \"luas_tanah\", \"kamar\", \"kamar_mandi\", \"listrik\", \"interior\", \"sertifikat\", \"parkir\"]]\n",
    "    y = data[\"harga\"]\n",
    "\n",
    "    # Encode categorical data\n",
    "    X_encoded = pd.get_dummies(X, columns=[\"lokasi\", \"interior\", \"sertifikat\"])\n",
    "\n",
    "    # Cache the preprocessed data\n",
    "    joblib.dump((data, X_encoded, y), data_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "X_train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the trained model is already available\n",
    "rf_model_cache_file = \"cache/rf_model_cache.joblib\"\n",
    "xgb_model_cache_file = \"cache/xgb_model_cache.joblib\"\n",
    "if file_exists(rf_model_cache_file):\n",
    "    best_rf_model = joblib.load(rf_model_cache_file)\n",
    "else:\n",
    "    # Perform hyperparameter tuning if the model is not cached\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [None, 10],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"min_samples_leaf\": [1, 2],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "    # Cache the trained model\n",
    "    joblib.dump(best_rf_model, rf_model_cache_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build XGB Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_exists(xgb_model_cache_file):\n",
    "    best_xgb_model = joblib.load(xgb_model_cache_file)\n",
    "else:\n",
    "    # Perform hyperparameter tuning for XGBRegressor if the model is not cached\n",
    "    param_grid_xgb = {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [3, 6],\n",
    "        \"learning_rate\": [0.1, 0.01],\n",
    "        \"gamma\": [0, 0.1],\n",
    "    }\n",
    "\n",
    "    grid_search_xgb = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid_xgb, cv=10)\n",
    "    grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "    best_xgb_model = grid_search_xgb.best_estimator_\n",
    "    print(\"Best parameters for XGBRegressor:\", grid_search_xgb.best_params_)\n",
    "\n",
    "    # Cache the trained XGBRegressor model\n",
    "    joblib.dump(best_xgb_model, xgb_model_cache_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict using the combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rf = best_rf_model.predict(X_train)\n",
    "y_train_pred_xgb = best_xgb_model.predict(X_train)\n",
    "\n",
    "X_train_combined = pd.DataFrame({\n",
    "    \"RF_Prediction\": y_train_pred_rf,\n",
    "    \"XGB_Prediction\": y_train_pred_xgb\n",
    "})\n",
    "\n",
    "y_test_pred_rf = best_rf_model.predict(X_test)\n",
    "y_test_pred_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "X_test_combined = pd.DataFrame({\n",
    "    \"RF_Prediction\": y_test_pred_rf,\n",
    "    \"XGB_Prediction\": y_test_pred_xgb\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a meta-model (RandomForestRegressor) on the combined predictions\n",
    "meta_model = RandomForestRegressor(random_state=42)\n",
    "meta_model.fit(X_train_combined, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate the meta-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = mean_squared_error(y_train, meta_model.predict(X_train_combined), squared=False)\n",
    "train_r2 = r2_score(y_train, meta_model.predict(X_train_combined))\n",
    "train_mae = mean_absolute_error(y_train, meta_model.predict(X_train_combined))\n",
    "test_rmse = mean_squared_error(y_test, meta_model.predict(X_test_combined), squared=False)\n",
    "test_r2 = r2_score(y_test, meta_model.predict(X_test_combined))\n",
    "test_mae = mean_absolute_error(y_test, meta_model.predict(X_test_combined))\n",
    "\n",
    "print(\"Combined Model:\\n\")\n",
    "print(\"Training RMSE:\", train_rmse)\n",
    "print(\"Training R2 Score:\", train_r2)\n",
    "print(\"Training MAE:\", train_mae)\n",
    "print(\"\\n\")\n",
    "print(\"Testing RMSE:\", test_rmse)\n",
    "print(\"Testing R2 Score:\", test_r2)\n",
    "print(\"Testing MAE:\", test_mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Predict with Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict house price\n",
    "new_data = pd.DataFrame({\n",
    "    \"lokasi_Sleman\": [0],\n",
    "    \"lokasi_Yogyakarta\": [0],\n",
    "    \"lokasi_Kulon Progo\": [0],\n",
    "    \"lokasi_Bantul\": [1],\n",
    "    \"lokasi_Wates\": [0],\n",
    "    \"luas_bangunan\": [1000],\n",
    "    \"luas_tanah\": [1248],\n",
    "    \"kamar\": [8],\n",
    "    \"kamar_mandi\": [9],\n",
    "    \"listrik\": [22000],\n",
    "    \"interior_Tak Berperabot\": [0],\n",
    "    \"interior_Lengkap\": [1],\n",
    "    \"interior_Sebagian\": [0],\n",
    "    \"parkir\": [2],\n",
    "    \"sertifikat_SHM - Sertifikat Hak Milik\": [1],\n",
    "    \"sertifikat_SHGB - Hak Guna Bangunan\": [0],\n",
    "    \"sertifikat_Sertifikat Belum Pecah\": [0],\n",
    "})\n",
    "\n",
    "# Reorder the columns to match the order used during training\n",
    "new_data = new_data[X_encoded.columns]\n",
    "\n",
    "new_data_pred_rf = best_rf_model.predict(new_data)\n",
    "new_data_pred_xgb = best_xgb_model.predict(new_data)\n",
    "\n",
    "new_data_combined = pd.DataFrame({\n",
    "    \"RF_Prediction\": new_data_pred_rf,\n",
    "    \"XGB_Prediction\": new_data_pred_xgb\n",
    "})\n",
    "\n",
    "new_data_pred = meta_model.predict(new_data_combined)\n",
    "print(\"Predicted house price:\", new_data_pred[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
